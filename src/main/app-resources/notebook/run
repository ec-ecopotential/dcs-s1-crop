#!/opt/anaconda/bin/python

import sys
reload(sys)
sys.setdefaultencoding('utf8')
import os
import io
import shutil
import urllib
import atexit
from nbconvert.preprocessors import ExecutePreprocessor, CellExecutionError
import nbformat as nbf
import uuid
import re
import lxml.etree as etree
import requests
import warnings
warnings.filterwarnings("ignore")

sys.path.append('/opt/anaconda/bin/')
import cioppy
ciop = cioppy.Cioppy()

import StringIO
import configparser
import pysftp
import traceback
import ast

import zipfile

# define the exit codes
SUCCESS = 0
ERR_NB_RUNTIME = 10
ERR_GET_CAT = 20
ERR_IMPORT_CAT = 30
RUNTIME_ERR = 40

references = []
identifiers = []
enclosures = []
local_files = [] 

# add a trap to exit gracefully
def clean_exit(exit_code):
    log_level = 'INFO'
    if exit_code != SUCCESS:
        log_level = 'ERROR'  
   
    msg = {SUCCESS: 'Processing successfully concluded',
           ERR_NB_RUNTIME: 'Failed to run notebook',
           ERR_GET_CAT: 'Error in catalog get',
           ERR_IMPORT_CAT: 'Error in catalog import',
           RUNTIME_ERR: 'Processing failed'
    }
 
    ciop.log(log_level, msg[exit_code])  
    
def parametrize(identifier, pa_series, wkt, pa_name, ftp_server_address):
    
    global nb
    
    for index, cell in enumerate(nb['cells']):
       
        if str(cell['cell_type']) == 'code': 
        
            try:
                root_ast = ast.parse(str(cell['source']))
                names = list({node.id for node in ast.walk(root_ast) if isinstance(node, ast.Name)})
                
                if len(names) == 1:
                    
                    if names[0] == 'data_path':
                        ciop.log('INFO', 'cell %s updated with \'data_path\' value %s' % (index, tmp_dir))
                        cell['source'] = 'data_path = \'%s\'' % tmp_dir  
        
                    if names[0] == 'input_identifier':
                        ciop.log('INFO', 'cell %s updated with \'input_identifier\' value %s' % (index, identifier))
                        cell['source'] = 'input_identifier = \'%s\'' % identifier  
                
                    if names[0] == 'input_reference':
                        ciop.log('INFO', 'cell %s updated with \'input_reference\' value %s' % (index, pa_series))
                        cell['source'] = 'input_reference = \'%s\'' % pa_series
                        
                    if names[0] == 'input_identifier_wkt':
                        ciop.log('INFO', 'cell %s updated with \'input_identifier_wkt\' value %s' % (index, wkt))
                        cell['source'] = 'input_identifier_wkt = \'%s\'' % wkt
                
                    if names[0] == 'input_pa_name':
                        ciop.log('INFO', 'cell %s updated with \'input_pa_name\' value %s' % (index, pa_name))
                        cell['source'] = 'input_pa_name = \'%s\'' % pa_name
                        
                    if names[0] == 'input_ftp_server_address':
                        ciop.log('INFO', 'cell %s updated with \'input_ftp_server_address\' value %s' % (index, ftp_server_address))
                        cell['source'] = 'input_ftp_server_address = \'%s\'' % ftp_server_address
                        
                        
                if len(names) != 2:
                    continue
                
                if names[0] == 'dict' or names[1] == 'dict':
                    
                    # deal with the alphabetical order
                    if names[1] == 'dict': 
                        names[1] = names[0]
                        names[0] = 'dict'
                
                    exec(str(cell['source'])) in globals(), locals()
                
                    if names[0] == 'dict' and 'title' in eval(names[1]).keys() and 'abstract' in eval(names[1]).keys() and 'id' in eval(names[1]).keys() and 'value' in eval(names[1]).keys():
                                      
                        eval(names[1])['value'] = ciop.getparam(eval(names[1])['id'])
    
                        new_source = 'dict(['

                        for i, keys in enumerate(eval(names[1])):
                            if i == 0: 
                                new_source = new_source + '( "%s", "%s")' % (keys, eval(names[1])[keys]) 
                            else:
                                new_source = new_source + ',( "%s", "%s")' % (keys, eval(names[1])[keys]) 
        
                        new_source = new_source + '])'
    
                        cell['source'] = '%s = %s' % (names[1], new_source)
         
                        ciop.log('INFO', 'cell %s %s updated' % (index, names[1]))
                    
            except SyntaxError:
                continue
        
        
        
def reproducibility(path, reference):
    
    ciop.log('INFO', 'Create stage-in notebook for reproducibility')
    
    global tmp_dir
        
    nb_stagein = nbf.v4.new_notebook()
    code = []
      
    code.append(nbf.v4.new_code_cell("""\
import os
import sys
sys.path.append('/opt/anaconda/bin/')
import cioppy
ciop = cioppy.Cioppy()"""))
    
    code.append(nbf.v4.new_code_cell('tmp_dir = "' + tmp_dir + '"'))
    code.append(nbf.v4.new_code_cell('os.makedirs(tmp_dir)'))
    
    code.append(nbf.v4.new_code_cell('reference = "' + reference + '"'))
    code.append(nbf.v4.new_code_cell("search = ciop.search(end_point = reference, params = [], output_fields='enclosure,identifier', model='GeoTime')"))
    code.append(nbf.v4.new_code_cell("retrieved = ciop.copy(search[0]['enclosure'], tmp_dir)"))
    code.append(nbf.v4.new_code_cell("assert(retrieved)"))
        
    nb_stagein['cells'] = code
    fname = os.path.join(path, 'stage-in.ipynb')
    with open(fname, 'w') as f:
        nbf.write(nb_stagein, f)
    

def stage_in(reference):
   
    search = ciop.search(end_point = reference, params = [], output_fields='enclosure,identifier', model='GeoTime')
    assert(search), sys.exit(ERR_RESOLUTION)
  
    ciop.log('INFO', 'Retrieving %s from %s' % (search[0]['identifier'], search[0]['enclosure']))  

    retrieved = ciop.copy(search[0]['enclosure'], tmp_dir, False)
        
    assert(retrieved), sys.exit(ERR_STAGEIN)
    
    identifiers.append(search[0]['identifier'])
    enclosures.append(search[0]['enclosure'])
    local_files.append(retrieved)        
    
    
def execute(identifier, pa_series, wkt, pa_name, ftp_server_address, nb_source, nb_target, kernel = 'python2'):
    
    global nb
   
    nb = nbf.read(nb_source, 4)
    
    ciop.log('INFO', 'Execute notebook')
    
    parametrize(identifier, pa_series, wkt, pa_name, ftp_server_address)
    
    # execute the notebook
    ep = ExecutePreprocessor(timeout=None, kernel_name=kernel)

    try:
        out = ep.preprocess(nb, {'metadata': {'path': './'}})
    except CellExecutionError:
        out = None
        ciop.log('ERROR', 'Error executing the notebook "%s".' % nb_source)

        with io.open(nb_target, 'wb') as file:
            file.write(nbf.writes(nb))
            file.close()
      
        ciop.publish(nb_target, metalink=True)
        raise
    finally:
        ciop.log('INFO', 'Write notebook')  
        with io.open(nb_target, 'wb') as file:
            file.write(nbf.writes(nb))
            file.close() 

def publish(runtime):
   
    # publish
    ciop.log('INFO', 'Publishing ') 
    ciop.publish(runtime, metalink=True, recursive=True)
    
    
def sftp_upload(products_path, hostname, user, passwd, target_dir):

    print 'INFO', 'Connecting to %s to publish %s' % (hostname, products_path)

    try:
        cnopts = pysftp.CnOpts()
        cnopts.hostkeys = None
        with pysftp.Connection(hostname, username=user, password=passwd, cnopts=cnopts) as sftp:
            sftp.makedirs(target_dir)
            sftp.chdir(target_dir)
            for data in products_path:
                sftp.put(data, preserve_mtime=True)
    except IOError as e:
        print 'ERROR', 'Unexpected error: %s' % e
        print 'ERROR', ''.join(traceback.format_stack())
        return False
    except Exception as e:
        print 'ERROR', 'Unexpected error: %s' % e
        print 'ERROR', ''.join(traceback.format_stack())
        return False
    return True    


def post_request(endpoint, data, auth, headers={}):
    return requests.post(endpoint ,
                         data=data,
                         headers=headers,
                         auth=auth)


def update_atom(atom, hostname, remote_path, product):
                     
    my_target_enclosure = 'sftp://%s/%s/%s' %(hostname, remote_path, product)
    
    new_identifier = os.path.splitext(product)[0]
    
    ciop.log('DEBUG','new_identifier : %s' %new_identifier)
    
    root = etree.fromstring(atom)
    
    enclosure_elem = root.xpath('/a:feed/a:entry/a:link[@title="Download via Data Gateway"]', 
                             namespaces={'a':'http://www.w3.org/2005/Atom'})

    eop_id_elem = root.xpath('/a:feed/a:entry/s:EarthObservation/e:metaDataProperty/e:EarthObservationMetaData/e:identifier', 
                             namespaces={'a':'http://www.w3.org/2005/Atom',
                                         'e':'http://www.opengis.net/eop/2.1',
                                         's':'http://www.opengis.net/sar/2.1'})

    id_elem = root.xpath('/a:feed/a:entry/d:identifier', 
                         namespaces={'a':'http://www.w3.org/2005/Atom',
                                     'd':'http://purl.org/dc/elements/1.1/'})

    enclosure_elem[0].attrib['title'] =  'Download via %s server' %hostname
    enclosure_elem[0].attrib['href'] =  my_target_enclosure
    
    eop_id_elem[0].text = new_identifier
   
    id_elem[0].text = new_identifier

    ciop.log('INFO','ATOM UPDATED')
    
    return etree.tostring(root, pretty_print=True)
    
    
def catalog_publish(reference, product, index, hostname, remote_path, username, api_key):
    
    exit_v = 0   
    ciop.log('DEBUG','product : %s' %product)
    ciop.log('DEBUG','reference : %s' %reference)
    try:
        atom = ciop.search(reference, params = [], output_fields='{}', model='EOP')
    except Exception as e:
        ciop.log('ERROR', 'An error occurred while retrieving atom for %s' %reference)
        raise SystemExit(ERR_GET_CAT)
                     
    new_atom = update_atom(atom, hostname, remote_path, product)
                     
    endpoint = 'https://catalog.terradue.com/%s' % index

    headers = {"Content-Type": "application/atom+xml", "Accept": "application/xml"}
                
    try:
        request_track = post_request(endpoint ,
                                     new_atom,
                                     (username, api_key),
                                     headers)
    except Exception,e:
        ciop.log('ERROR', 'An error occured while registering %s in the index %s: \n %s' % (new_identifier,index,e))
        exit_v = 1

    if request_track.status_code != 200:
        ciop.log('WARN', 'Atom registration for %s FAILED (%s)' % (new_identifier,request_track.status_code))
        exit_v = 1
    
    return exit_v

    
def ecop_publish(runtime, reference, ftp_server, ftp_user, ftp_passwd, base_path, pa_name, index, username, api_key):

    exit_value = 0
    
    regexp = 'S1._.._...._...._([0-9]{4})([0-9]{2})([0-9]{2})T(.*)$'
    regexp0 = '(S1.*).*.zip$'
    
    dir_content = os.listdir(runtime)
    ciop.log('DEBUG','dir_content : %s' %dir_content)
    
    zip_files = filter(lambda x: x.endswith('.zip'), os.listdir(runtime))

    if len(zip_files) == 0:
        ciop.log('WARNING','No dataset downloaded')
        return 1

    product = zip_files[0]

    m = re.search(regexp0, product)

    assert m.groups()[0] == reference.split('=')[2], 'ERROR on data selection: %s != %s' %(m.groups()[0],reference.split('=')[2])
        
    m = re.search(regexp, product)
    date_path = '%s/%02d/%02d' % (m.groups()[0], int(m.groups()[1]), int(m.groups()[2]))
    
    ftp_index = reference.split('/')[3]
    if ftp_index == '':
        ftp_index = reference.split('/')[4]
    

    middle_path = '%s/%s/EO_Data/%s/Raw/'%(base_path, pa_name, ftp_index.capitalize())
        
    #remote_path = os.path.join(middle_path, os.path.join('test-t2',date_path))
    remote_path = os.path.join(middle_path, date_path)

    ciop.log('DEBUG','remote_path: %s' %remote_path)
    
    zip_path = os.path.join(runtime, product)
    
    xml_file = '%s.xml' %os.path.splitext(product)[0]
    xml_path = os.path.join(runtime, xml_file) 
    files = [xml_path, zip_path]
        
    if sftp_upload(files, ftp_server, ftp_user, ftp_passwd, remote_path):
        ciop.log('INFO','%s uploaded' % files)       
        out = catalog_publish(reference, product, index, ftp_server, remote_path, username, api_key)
        if (out == 1):
            ciop.log('ERROR','catalog publishing : FAILED')
            exit_value = 1
        else:
            ciop.log('INFO','catalog publishing : DONE')
    else:
        ciop.log('ERROR','%s NOT published' % zip_path)
        exit_value = 1
                    
    return exit_value
                     
def clean_up(runtime):
    
    # delete last retrieved file
    if os.path.isfile(local_files[-1]):
        os.remove(local_files[-1])
    elif  os.path.isdir(local_files[-1]):
        shutil.rmtree(local_files[-1])
    
    # clean-up 
    shutil.rmtree(runtime)

    
def main():

    # create the folder for the data stage-in
    global tmp_dir
    tmp_dir = os.path.join('/tmp', 'workspace-' + str(uuid.uuid4()), 'data') 
    os.makedirs(tmp_dir)
    start = ciop.getparam('start')
    stop = ciop.getparam('stop')
    time_filter_type = ciop.getparam('time_filter_type')
    cat_index = ciop.getparam('cat_index')
    config_url = ciop.getparam('config_url')
    username = ciop.getparam('username')
    api_key = ciop.getparam('api_key')
    base_endpoint = ciop.getparam('base_endpoint')

    try:
        r = requests.get(config_url, headers={"X-JFrog-Art-Api":api_key, 'User-Agent': 'curl/t2Client'})

        ini_content = ''

        if r.status_code == 200:
            ini_content = r.content

        if not ini_content:
            raise ValueError

        # read the configuration values
        buf = StringIO.StringIO(ini_content)
        config = configparser.ConfigParser()
        config.readfp(buf)

        ftp_server = str(config.get('ftp', 'hostname'))
        ftp_user = str(config.get('ftp', 'user'))
        ftp_passwd = str(config.get('ftp', 'passwd'))
        base_path=str(config.get('ftp', 'base_path'))
        
    except Exception as e:
        ciop.log('ERROR', 'An error occurred while getting ftp config:\n %s' %e)
        raise SystemExit(RUNTIME_ERR)
    
    
    
    
    # Loops over all the inputs
    for input in sys.stdin:
        
        pa_series_identifier = input.rstrip()
        ciop.log('DEBUG', 'current pa series identifier: %s' %pa_series_identifier)
        
        pa_name = str(config.get(pa_series_identifier, 'pa_name'))
        pa_code = str(config.get(pa_series_identifier, 'pa_code'))
        pa_wkt = str(config.get(pa_series_identifier, 'pa_wkt'))
        spatialCover = str(config.get(pa_series_identifier, 'spatialCover'))
        
        params = dict([('start', start),
                   ('stop', stop),
                   ('spatialCover',spatialCover),
                   ('count',10000)])
        if time_filter_type == 'update':
            params = dict([('update', '%s/%s' %(start,stop)),
                   ('spatialCover',spatialCover),
                   ('count',10000)])
        
        endpoint = '%s?geom=%s&correlatedTo=https://catalog.terradue.com/ecop-cnr-issia/series/pa/search?uid=%s&corFunction=spatial' %(base_endpoint,urllib.quote(pa_wkt),pa_series_identifier)
        
        
        try:

            references = ciop.search(endpoint, params = params, output_fields='self,wkt')
            
        except IndexError:
            ciop.log('INFO', 'No datasets found for %s' %reference_input)
            continue
        except Exception as e:
            ciop.log('ERROR', 'An error occurred while looking for datasets over %s: \n %s' %(pa_series_identifier,e))
            raise SystemExit(ERR_GET_CAT)
    
        for ref in references:

            reference = ref['self']
            #if crop_flag is False no need to unxzip the dataset: it is uploaded as it is
            #ciop.log('INFO', 'downloading dataset (unzipping = %s)' %crop_flag)
            ciop.log('INFO', 'downloading dataset %s' %reference)
            stage_in(reference)
            
            runtime = os.path.join(ciop.tmp_dir, str(uuid.uuid4()))    

            os.makedirs(runtime)
            #os.makedirs('%s/%s'%(runtime,identifiers[-1]))
            os.chdir(runtime)

            reproducibility(runtime, reference)
            # execute the notebook
            nb_source = os.path.join('/application', 'notebook', 'libexec', 'input.ipynb')
            nb_target = os.path.join(runtime, 'result.ipynb')
            
            
            #ftp_server_basepath = 'sftp://frontend.recas.ba.infn.it/lustre/ecopotential/incoming/PAs'
            ftp_server_address = 'sftp://%s%s' %(ftp_server, base_path)
            
            execute(identifiers[-1], pa_series_identifier, ref['wkt'], pa_name, ftp_server_address, nb_source, nb_target, 'python2')
                
            try:
                # ecopotential publish consisting of cnr ftp uploading and atom publish on the related catalog index 
                ecop_publish(runtime, reference, ftp_server, ftp_user, ftp_passwd, base_path, pa_name, cat_index, username, api_key)
            except Exception as e:
                ciop.log('ERROR', 'Error publishing data on the ftp server : \n %s' %e)
                continue
            finally:
                # clean-up 
                clean_up(runtime)

    # clean-up workspace folder
    ciop.log('DEBUG', 'Finally removing : %s' %os.path.split(tmp_dir)[0])
    shutil.rmtree(os.path.split(tmp_dir)[0])
try:
    main()
except SystemExit as e:
    if e.args[0]:
          clean_exit(e.args[0])
    raise
else:
    atexit.register(clean_exit, 0)


